{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gopivardhangunta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At last he managed to scramble out, and as he stood sadly thinking about the good bone he had lost,\n",
      " he realized what a stupid Dog he had been.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "#preprocessing the text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return inputs['input_ids'], inputs['attention_mask']\n",
    "\n",
    "def get_embeddings(text):\n",
    "    input_ids, attention_mask = preprocess_text(text)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "def extractive_summarization(text, num_sentences=1):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    sentence_embeddings = [get_embeddings(sentence).numpy().mean(axis=1) for sentence in sentences]\n",
    "    text_embedding = get_embeddings(text).numpy().mean(axis=1)\n",
    "    \n",
    "    similarities = [cosine_similarity(text_embedding, sentence_embedding)[0][0] for sentence_embedding in sentence_embeddings]\n",
    "    \n",
    "    ranked_sentences = [sentences[i] for i in np.argsort(similarities)[-num_sentences:]]\n",
    "    return ' '.join(ranked_sentences)\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text = \"\"\"A Dog, to whom the butcher had thrown a bone, was hurrying home with his prize as fast as he could go. As he crossed a narrow footbridge,\n",
    " he happened to look down and saw himself reflected in the quiet water as if in a mirror. But the greedy Dog thought he saw a real Dog carrying a bone\n",
    " much bigger than his own. If he had stopped to think he would have known better. But instead of thinking, he dropped his bone and sprang at the Dog in the river,\n",
    " only to find himself swimming for dear life to reach the shore. At last he managed to scramble out, and as he stood sadly thinking about the good bone he had lost,\n",
    " he realized what a stupid Dog he had been.\"\"\"\n",
    "summary = extractive_summarization(text)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
